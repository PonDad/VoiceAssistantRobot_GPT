'''
bot_face_track_recognizer.py

ã‚«ãƒ¡ãƒ©æ˜ åƒã‚’å–å¾—ã—ã€é¡”ã‚’æ¤œå‡ºã—ã¦èªè­˜ã™ã‚‹é¡”è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒœãƒƒãƒˆç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™
ã‚«ãƒ¡ãƒ©ã§é¡”ã‚’æ¤œå‡ºã—ã€é¡”ã®ç‰¹å¾´ã‚’æŠ½å‡ºã—ã¦è¾žæ›¸ã¨æ¯”è¼ƒã—ã€é¡”èªè­˜ã‚’è¡Œã„ã¾ã™
ã¾ãŸã€é¡”ã®ä¸­å¿ƒã‚’æ‰ãˆã¦ã‚«ãƒ¡ãƒ©ã®ãƒ‘ãƒ³ã¨ãƒãƒ«ãƒˆã‚’åˆ¶å¾¡ã—ã€é¡”ã®è¿½è·¡ã‚‚è¡Œã„ã¾ã™
'''

import cv2
import numpy as np
import time
from pathlib import Path
from collections import Counter
from bot_motor_controller import pan_tilt, neopixels_all, neopixels_off

class Camera():
    def __init__(self):
        self.cap = cv2.VideoCapture(0) 
        self.cap.set(3, 640)  
        self.cap.set(4, 480)

    def get_frame(self):
        ret, frame = self.cap.read()
        if ret: 
            return frame
        else:
            print("ðŸ’» SYSTEM: ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return None

    def release_camera(self):
        self.cap.release()

def face_recognize():
    # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    face_detector_weights = str(Path("dnn_models/yunet.onnx").resolve())
    #face_detector_weights = str(Path("dnn_models/yunet_s_640_640.onnx").resolve())  # é¡”æ¤œå‡ºç”¨ã®weights
    face_detector = cv2.FaceDetectorYN_create(face_detector_weights, "", (0, 0))

    # é¡”è­˜åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    face_recognizer_weights = str(Path("dnn_models/face_recognizer_fast.onnx").resolve())  # é¡”èªè­˜ç”¨ã®weights
    face_recognizer = cv2.FaceRecognizerSF_create(face_recognizer_weights, "")

    COSINE_THRESHOLD = 0.363
    #NORML2_THRESHOLD = 1.128

    # ç‰¹å¾´ã‚’èª­ã¿è¾¼ã¿ç‰¹å¾´é‡è¾žæ›¸ã‚’ã¤ãã‚‹
    dictionary = []
    files = Path("face_dataset").glob("*.npy")
    for file in files:
        feature = np.load(file)
        user_id = Path(file).stem
        dictionary.append((user_id, feature))

    # ç‰¹å¾´ã‚’è¾žæ›¸ã¨æ¯”è¼ƒã—ã¦ãƒžãƒƒãƒã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¹ã‚³ã‚¢ã‚’è¿”ã™é–¢æ•°
    def match(recognizer, feature1, data_directory):
        for element in data_directory:
            user_id, feature2 = element
            score = recognizer.match(feature1, feature2, cv2.FaceRecognizerSF_FR_COSINE)
            if score > COSINE_THRESHOLD:
                return True, (user_id, score)
        return False, ("", 0.0)
    
    recognized_ids =[]
    
    # ã‚«ãƒ¡ãƒ©ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ãƒ³/ãƒãƒ«ãƒˆ (åº¦å˜ä½)ã€‚ã‚³ãƒ¼ãƒ‰ã‚’é–‹å§‹ã™ã‚‹ã¨ãã«ã€ãŠãŠã‚ˆãã®é¡”ã®ä½ç½®ã‚’æŒ‡ã™ã‚ˆã†ã«è¨­å®šã—ã¾ã—ãŸ
    # ã‚«ãƒ¡ãƒ©ã®ç¯„å›²ã¯ 0 ï½ž 180 ã§ã™ã€‚ä»¥ä¸‹ã®å€¤ã‚’å¤‰æ›´ã—ã¦ã€ãƒ‘ãƒ³ã¨ãƒãƒ«ãƒˆã®é–‹å§‹ç‚¹ã‚’æ±ºå®šã—ã¾ã™ã€‚
    cam_pan = 90
    cam_tilt = 60
    # ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ä½ç½®ã«å‘ã‘ã¾ã™ (pan() é–¢æ•°ã¨tilt() é–¢æ•°ãŒæœŸå¾…ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ -90 åº¦ã‹ã‚‰ 90 åº¦ã¾ã§ã®ä»»æ„ã®æ•°å€¤ã§ã™)
    pan_tilt(cam_pan-90,cam_tilt-90)

    cam = Camera()  # ã‚«ãƒ¡ãƒ©ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    neopixels_all(50, 50, 50)

    time_start = time.perf_counter()
    time_end = 0

    while True:
        frame = cam.get_frame()  # ã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
        frame = cv2.flip(frame, -1)  # ã‚«ãƒ¡ãƒ©ç”»åƒã®ä¸Šä¸‹ã‚’å…¥ã‚Œæ›¿ãˆã‚‹

        # å…¥åŠ›ã‚µã‚¤ã‚ºã‚’æŒ‡å®šã™ã‚‹
        height, width, _ = frame.shape
        face_detector.setInputSize((width, height))

        # é¡”ã‚’æ¤œå‡ºã™ã‚‹
        _, faces = face_detector.detect(frame)
        faces = faces if faces is not None else []

        # æ¤œå‡ºã—ãŸé¡”ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã¨ãƒ©ãƒ³ãƒ‰ãƒžãƒ¼ã‚¯ã‚’æç”»ã™ã‚‹
        frame_output = frame.copy()

        for face in faces:
            # é¡”ã‚’åˆ‡ã‚ŠæŠœãç‰¹å¾´ã‚’æŠ½å‡ºã™ã‚‹
            aligned_face = face_recognizer.alignCrop(frame, face)
            feature = face_recognizer.feature(aligned_face)

            # è¾žæ›¸ã¨ãƒžãƒƒãƒãƒ³ã‚°ã™ã‚‹
            result, user = match(face_recognizer, feature, dictionary)

            # ãƒžãƒƒãƒãƒ³ã‚°ã—ãŸã‚‰ãƒœãƒƒã‚¯ã‚¹ã¨ãƒ†ã‚­ã‚¹ãƒˆã®è‰²ã‚’å¤‰ãˆã‚‹
            if result is True:
                color = (0,255,0)
                neopixels_all(0, 50, 0)
            else:
                color = (255,255,255)
                neopixels_all(50, 50, 50)

            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
            x, y, w, h = list(map(int, face[:4]))
            thickness = 1
            cv2.rectangle(frame_output, (x, y), (x + w, y + h), color, thickness, cv2.LINE_AA)

            # ãƒ©ãƒ³ãƒ‰ãƒžãƒ¼ã‚¯ï¼ˆå³ç›®ã€å·¦ç›®ã€é¼»ã€å³å£è§’ã€å·¦å£è§’ï¼‰
            landmarks = list(map(int, face[4:len(face)-1]))
            landmarks = np.array_split(landmarks, len(landmarks) / 2)
            for landmark in landmarks:
                radius = 3
                thickness = -1
                cv2.circle(frame_output, landmark, radius, color, thickness, cv2.LINE_AA)
            
            # èªè­˜ã®çµæžœã‚’æç”»ã™ã‚‹
            id, score = user if result else ("unknown", 0.0)
            text = "{0} ({1:.2f})".format(id, score)
            position = (x, y - 10)
            font = cv2.FONT_HERSHEY_SIMPLEX
            scale = 0.6
            thickness = 1
            cv2.putText(frame_output, text, position, font, scale, color, thickness, cv2.LINE_AA)

            # ãƒžãƒƒãƒãƒ³ã‚°ã—ãŸã‚‰IDã‚’ä¸€åº¦ã ã‘è¿½åŠ ã™ã‚‹
            if result:
                recognized_ids.append(id)
                #print(recognized_ids)

            # é¡”ã®ä¸­å¿ƒã‚’æ‰ãˆã‚‹
            x = x + (w/2)
            y = y + (h/2)

            # ç”»åƒã®ä¸­å¿ƒã‚’åŸºæº–ã¨ã—ã¦è£œæ­£
            turn_x  = float(x - (width / 2))
            turn_y  = float(y - (height / 2))

            # ã‚ªãƒ•ã‚»ãƒƒãƒˆãƒ»ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã«å¤‰æ›
            turn_x  /= float(width / 2)
            turn_y  /= float(height / 2)

            # Sã‚¹ã‚±ãƒ¼ãƒ«ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’åº¦æ•°ã«å¤‰æ›
            #ï¼ˆä¸‹ã®2.5ã®å€¤ã¯PIDã®æ¯”ä¾‹ä¿‚æ•°ã®ã‚ˆã†ãªåƒãã‚’ã—ã¾ã™ï¼‰
            turn_x   *= 2.5 # VFOV
            turn_y   *= 2.5 # HFOV
            cam_pan  += -turn_x
            cam_tilt += turn_y

            #print(cam_pan-90, cam_tilt-90)

            # ãƒ‘ãƒ³/ãƒãƒ«ãƒˆ0ï½ž180åº¦ ã«å›ºå®š
            cam_pan = max(0,min(180,cam_pan))
            cam_tilt = max(0,min(180,cam_tilt))

            # ã‚µãƒ¼ãƒœã®æ›´æ–°
            pan_tilt(int(cam_pan-90),int(cam_tilt-90))

            break
        
        if frame is not None:
            cv2.imshow("face detection", frame_output)

        time_end = time.perf_counter() - time_start
        if time_end > 5:
            break

        key = cv2.waitKey(1)
        if key == ord('q'):
            break

    cam.release_camera()  # ã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾
    cv2.destroyAllWindows()
    time.sleep(0.5)
    pan_tilt(0,0)
    time.sleep(0.5)
    neopixels_off()
    return Counter(recognized_ids).most_common()[0][0]

if __name__ == '__main__':
    recognized_id = face_recognize()
    print(recognized_id)