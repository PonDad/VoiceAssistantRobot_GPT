'''
bot_face_data_creator.py

ãƒœã‚¤ã‚¹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®é¡”èªè¨¼ã¨å¹´é½¢æ€§åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™
ã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¡”ã‚’æ¤œå‡ºã—ã€é¡”ç”»åƒã‚’åé›†ã—ã¦ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã€æ€§åˆ¥ã¨å¹´é½¢ã‚’æ¨è«–ã—ã¦JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™
é¡”èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„ãƒ‡ãƒ¼ã‚¿åé›†ã«ä½¿ç”¨ã—ã¾ã™
'''

import cv2
import numpy as np
import time, json
from pathlib import Path
from bot_motor_controller import pan_tilt, neopixels_all, neopixels_off

class Camera():
    def __init__(self):
        self.cap = cv2.VideoCapture(0) 
        self.cap.set(3, 640)  
        self.cap.set(4, 480)

    def get_frame(self):
        ret, frame = self.cap.read()
        if ret: 
            return frame
        else:
            print("ğŸ–¥ï¸ SYSTEM: ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return None

    def release_camera(self):
        self.cap.release()

# jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹é–¢æ•°
def save_json(id, name, image, feature, gender, age, category, interested):
    user = {id:{
        "id": id,
        "name": name,
        "image": image,
        "feature": feature,
        "gender": gender,
        "age": age,
        "category": category,
        "interested": interested
    }
    }

    isempty = Path("data/user_data.json").stat().st_size == 0

    if isempty is True:
        with open(Path("data/user_data.json"), "w") as file:
            json.dump(user, file, ensure_ascii=False, indent=4)
    else:
        with open(Path("data/user_data.json")) as file:
            load_user = json.load(file)

        save_user = dict(load_user, **user)
        
        with open(Path("data/user_data.json"), 'w') as file:
            json.dump(save_user, file, ensure_ascii=False, indent=4)

def face_date_create():
    # é¡”èªè­˜ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    face_detector_weights = str(Path("dnn_models/yunet.onnx").resolve())
    #face_detector_weights = str(Path("dnn_models/yunet_s_640_640.onnx").resolve())
    face_detector = cv2.FaceDetectorYN_create(face_detector_weights, "", (0, 0))

    # é¡”è­˜åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    face_recognizer_weights = str(Path("dnn_models/face_recognizer_fast.onnx").resolve())
    face_recognizer = cv2.FaceRecognizerSF_create(face_recognizer_weights, "")

    # å¹´é½¢è­˜åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    ageProto = str(Path("dnn_models/age_deploy.prototxt").resolve())
    ageModel = str(Path("dnn_models/age_net.caffemodel").resolve())

    # æ€§åˆ¥è­˜åˆ¥ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    genderProto = str(Path("dnn_models/gender_deploy.prototxt").resolve())
    genderModel = str(Path("dnn_models/gender_net.caffemodel").resolve())

    MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)
    ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']
    genderList = ['male', 'female']

    # DNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«æ¥ç¶š
    ageNet = cv2.dnn.readNet(ageModel, ageProto)
    genderNet = cv2.dnn.readNet(genderModel, genderProto)

    # CPUä½¿ç”¨ã‚’æŒ‡å®š
    ageNet.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)
    genderNet.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–
    user_id = ""
    user_name = ""
    user_image = ""
    user_feature = ""
    user_gender = ""
    user_age = ""
    user_category = ""
    user_interested = ""

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã€ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã®å…¥åŠ›
    print("ğŸ–¥ï¸ SYSTEM: ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’ã²ã‚‰ãŒãªï¼ˆã¾ãŸã¯ã‚«ã‚¿ã‚«ãƒŠï¼‰ã§å…¥åŠ›ã—ã¦Eterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    user_name = input("> ")
    print("ğŸ–¥ï¸ SYSTEM: ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆï¼ˆæ­£è¦è¡¨ç¾ï¼‰ã§å…¥åŠ›ã—ã¦Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    user_id = input("> ")
    print("ğŸ–¥ï¸ SYSTEM: èˆˆå‘³ã®ã‚ã‚‹ã“ã¨ã‚’ã²ã¨ã¤å…¥åŠ›ã—ã¦Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    user_interested = input("> ")
    print("ğŸ–¥ï¸ SYSTEM: ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ æ’®å½±ã—ã¾ã™\næ’®å½±ã¯Sã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„\nçµ‚äº†ã¯Qã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")

    # ã‚«ãƒ¡ãƒ©ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ãƒ³/ãƒãƒ«ãƒˆ (åº¦å˜ä½)ã€‚ã‚³ãƒ¼ãƒ‰ã‚’é–‹å§‹ã™ã‚‹ã¨ãã«ã€ãŠãŠã‚ˆãã®é¡”ã®ä½ç½®ã‚’æŒ‡ã™ã‚ˆã†ã«è¨­å®šã—ã¾ã—ãŸ
    # ã‚«ãƒ¡ãƒ©ã®ç¯„å›²ã¯ 0 ï½ 180 ã§ã™ã€‚ä»¥ä¸‹ã®å€¤ã‚’å¤‰æ›´ã—ã¦ã€ãƒ‘ãƒ³ã¨ãƒãƒ«ãƒˆã®é–‹å§‹ç‚¹ã‚’æ±ºå®šã—ã¾ã™ã€‚
    cam_pan = 90
    cam_tilt = 60
    # ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ä½ç½®ã«å‘ã‘ã¾ã™ (pan() é–¢æ•°ã¨tilt() é–¢æ•°ãŒæœŸå¾…ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ -90 åº¦ã‹ã‚‰ 90 åº¦ã¾ã§ã®ä»»æ„ã®æ•°å€¤ã§ã™)
    pan_tilt(cam_pan-90,cam_tilt-90)

    cam = Camera()  # ã‚«ãƒ¡ãƒ©ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    neopixels_all(50, 50, 50)

    while(True):
        frame = cam.get_frame()  # ã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
        frame = cv2.flip(frame, -1)  # ã‚«ãƒ¡ãƒ©ç”»åƒã®ä¸Šä¸‹ã‚’å…¥ã‚Œæ›¿ãˆã‚‹

        # å…¥åŠ›ã‚µã‚¤ã‚ºã‚’æŒ‡å®šã™ã‚‹
        height, width, _ = frame.shape
        face_detector.setInputSize((width, height))

        # é¡”ã‚’æ¤œå‡ºã™ã‚‹
        _, faces = face_detector.detect(frame)
        faces = faces if faces is not None else []

        # æ¤œå‡ºã—ãŸé¡”ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã¨ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»ã™ã‚‹
        frame_output = frame.copy() 

        for face in faces:
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
            x, y, w, h = list(map(int, face[:4]))
            color = (255, 255, 255)
            thickness = 1
            cv2.rectangle(frame_output, (x, y), (x + w, y + h), color, thickness, cv2.LINE_AA)

            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ï¼ˆå³ç›®ã€å·¦ç›®ã€é¼»ã€å³å£è§’ã€å·¦å£è§’ï¼‰
            landmarks = list(map(int, face[4:len(face)-1]))
            landmarks = np.array_split(landmarks, len(landmarks) / 2)
            for landmark in landmarks:
                radius = 3
                thickness = -1
                cv2.circle(frame_output, landmark, radius, color, thickness, cv2.LINE_AA)
            
            # é¡”ã®ä¸­å¿ƒã‚’æ‰ãˆã‚‹
            x = x + (w/2)
            y = y + (h/2)

            # ç”»åƒã®ä¸­å¿ƒã‚’åŸºæº–ã¨ã—ã¦è£œæ­£
            turn_x  = float(x - (width / 2))
            turn_y  = float(y - (height / 2))

            # ã‚ªãƒ•ã‚»ãƒƒãƒˆãƒ»ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã«å¤‰æ›
            turn_x  /= float(width / 2)
            turn_y  /= float(height / 2)

            # Sã‚¹ã‚±ãƒ¼ãƒ«ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’åº¦æ•°ã«å¤‰æ›
            #ï¼ˆä¸‹ã®2.5ã®å€¤ã¯PIDã®æ¯”ä¾‹ä¿‚æ•°ã®ã‚ˆã†ãªåƒãã‚’ã—ã¾ã™ï¼‰
            turn_x   *= 2.5 # VFOV
            turn_y   *= 2.5 # HFOV
            cam_pan  += -turn_x
            cam_tilt += turn_y

            # ãƒ‘ãƒ³/ãƒãƒ«ãƒˆ0ï½180åº¦ ã«å›ºå®š
            cam_pan = max(0,min(180,cam_pan))
            cam_tilt = max(0,min(180,cam_tilt))

            # ã‚µãƒ¼ãƒœã®æ›´æ–°
            pan_tilt(int(cam_pan-90),int(cam_tilt-90))

            break

        # ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹
        cv2.imshow("face data create", frame_output)
        key = cv2.waitKey(10)

        if key == ord('s'):
            # æ¤œå‡ºã•ã‚ŒãŸé¡”ã‚’åˆ‡ã‚ŠæŠœã
            aligned_faces = []
            if faces is not None:
                for face in faces:
                    aligned_face = face_recognizer.alignCrop(frame, face)
                    aligned_faces.append(aligned_face)

            # ç”»åƒã‚’ä¿å­˜ã™ã‚‹
            for i, aligned_face in enumerate(aligned_faces):
                user_image = user_id + ".jpg"
                cv2.imwrite((str(Path("face_dataset/" + user_image))), aligned_face)
                cv2.imshow("aligned_face", aligned_face)
            
                # ç‰¹å¾´ã‚’æŠ½å‡ºã™ã‚‹
                aligned_face_img = cv2.imread(str(Path("face_dataset/" + user_image)))
                face_feature = face_recognizer.feature(aligned_face_img)

                # ç‰¹å¾´ã‚’ä¿å­˜ã™ã‚‹
                user_feature = user_id + ".npy"
                dictionary = Path("face_dataset/" + user_feature)
                np.save(dictionary , face_feature)

            # æ€§åˆ¥ã‚’æ¨è«–ã™ã‚‹
            blob = cv2.dnn.blobFromImage(frame_output, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)
            genderNet.setInput(blob)
            genderPreds = genderNet.forward()
            user_gender = genderList[genderPreds[0].argmax()]
            print("ğŸ–¥ï¸ SYSTEM: æ€§åˆ¥ : {}, conf = {:.3f}".format(user_gender, genderPreds[0].max()))

            # å¹´é½¢ã‚’æ¨è«–ã™ã‚‹
            ageNet.setInput(blob)
            agePreds = ageNet.forward()
            user_age = ageList[agePreds[0].argmax()]
            print("ğŸ–¥ï¸ SYSTEM: å¹´é½¢ : {}, conf = {:.3f}".format(user_age, agePreds[0].max()))

            # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†é¡
            if user_age in ageList[:4]:
                if user_gender == "male":
                    user_category = "boy"
                else:
                    user_category = "girl"
            elif user_age in ageList[4: 8]:
                if user_gender == "male":
                    user_category = "man"
                else:
                    user_category = "woman"

            # jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹
            save_json(user_id, user_name, user_image, user_feature, user_gender, user_age, user_category, user_interested)
            print("ğŸ–¥ï¸ SYSTEM: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿\n"
                  f"ID: {user_id} \n"
                  f"åå‰: {user_name} \n"
                  f"å†™çœŸ: {user_image} \n"
                  f"ç‰¹å¾´é‡: {user_feature} \n"
                  f"æ€§åˆ¥: {user_gender} \n"
                  f"å¹´é½¢: {user_age} \n"
                  f"åˆ†é¡: {user_category} \n"
                  f"èˆˆå‘³: {user_interested} \n"
                  "ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

        if key == ord('q'):
            print("ğŸ–¥ï¸ SYSTEM: æ’®å½±ã‚’çµ‚äº†ã—ã¾ã™")
            break

    cam.release_camera()  # ã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾
    cv2.destroyAllWindows()
    time.sleep(0.5)
    pan_tilt(0,0)
    time.sleep(0.5)
    neopixels_off()

if __name__ == '__main__':
    face_date_create()
